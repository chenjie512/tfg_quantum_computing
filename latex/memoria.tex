\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}


\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{braket}
\usepackage{comment}

\usepackage[qm]{qcircuit}

\usepackage{graphicx}
\graphicspath{ {./imagen/} }

%\usepackage{enumerate}
%\usepackage{blindtext}

\usepackage[left=3.25cm,top=3cm,right=2cm,bottom=3.25cm]{geometry}

%Nuevos entornos
\newtheorem{deff}{Definición}[section]

%Enumeración
\numberwithin{equation}{section}

%Nuevo comandos
\newcommand\norm[1]{\lVert#1\rVert}

\title{Computación Cuántica}
\author{Chenjie Huang}
\date{}


%Documento

\begin{document}
\maketitle

\tableofcontents

\newpage

\thispagestyle{empty}

\newpage

\section{Introducción}

Alguna breve introducción y tal???

\subsection{Objetivos}

(Pendiente)

\begin{itemize}
\item Introducción a la computación cuántica. Como la metodología de trabajo. Teoría matemática, espacios de Hilbert y Producto tensorial.

\item Estructura básica, qubits, y puertas cuánticas.

\item Algoritmos cuánticos. Con ejemplos en qiskit.

\begin{itemize}
	\item Algoritmo de Deutsch
	\item Algoritmo de Deutsch-Jozsa
	\item Algoritmo de Búsqueda de Grover
	\item Algoritmo de Periodicidad de Simon
	\item Algoritmo de Factorización de Shor.
\end{itemize}

\end{itemize}

\subsection{Metodología}
Lectura parcial de los libros que ha recomendado el tutor, seguidos de su discusión e implementación en Qiskit.(?)

\section{Preliminares}

La Teoría Cuántica se apoya principalmente sobre álgebra lineal, concretamente sobre el espacio vectorial complejo de dimensión finita $\mathbb{C}^n$.
En esta sección que servirá como preliminares como indica el título, nos centraremos en la teoría de álgebra lineal sobre el espacio vectorial complejo. 

%Estudiaremos los conceptos básicos de este campo y describiremos la notación estándar utilizada en el área de estudio de la mecánica cuántica.%

El objetivo es conseguir que este apartado sirva a modo de fundamento y bases para secciones posteriores y también de consulta posteriormente.

\subsection{Espacios Vectoriales}

%Recordaremos la definición de espacio vectorial y nos familiarizaremos con la notación braket.%(???)

\begin{deff}

Un espacio vectorial sobre un cuerpo $\mathbb{K}$ es un conjunto no vacío $\mathbb{V}$, cuyo elementos llamaremos vectores, y llevan asociado dos operaciones, 
\begin{itemize}

\item La Suma, $\textbf{+}: \mathbb{V} \times \mathbb{V} \longrightarrow \mathbb{V}$

\item El Producto por un escalar, $\textbf{$\cdot$}:\mathbb{K} \times \mathbb{V} \longrightarrow \mathbb{V}$

\end{itemize}
tal que $(\mathbb{V},+)$ cumple las propiedades de formar un \textbf{grupo abeliano} y el producto por un escalar $\cdot$ cumpla las propiedades de:
\begin{itemize}

\item Existencia de elemento neutro:
\begin{equation}
\exists e \in \mathbb{K} \text{ tal que } \forall v \in \mathbb{V},  e \cdot v = v
\end{equation}

\item Propiedad asociativa:
\begin{equation}
\forall a, b \in \mathbb{K}, \forall v \in \mathbb{V}, a\cdot(b\cdot v) = (a\cdot b)\cdot v
\end{equation}

\item Propiedad distributiva respecto a la suma de vectores:
\begin{equation}
\forall a \in \mathbb{K}, \forall u, v \in \mathbb{V}, a\cdot(u + v) = a\cdot u + a\cdot v
\end{equation}

\item Propiedad distributiva respecto a la suma de escalares:
\begin{equation}
\forall a, b \in \mathbb{K}, \forall v \in \mathbb{V}, (a + b)\cdot v = a\cdot v + b\cdot v
\end{equation}

\end{itemize}

\end{deff}

En el caso de que el cuerpo de escalares sea el de los complejos $\mathbb{C}$, se le denominará \textbf{espacio vectorial complejo}, siendo estas de gran interés para nuestro campo de estudio que es la mecánica cuántica.

A partir de ahora usaremos $\mathbb{C}$ como cuerpo de escalares del espacio vectorial junto a la notación estándar de mecánica cuántica para referirnos a los elementos básicos de la álgebra lineal.

Denotaremos al vector en un espacio vectorial $\mathbb{V}$ como $\ket{v}$, donde usaremos $\ket{\cdot}$ para indicar que es un vector del espacio, denominado \textbf{\textit{ket}}.

En cuanto al elemento neutro del espacio vectorial, el vector cero, lo denotaremos excepcionalmente como $\mathbf{0}$. Veremos posteriormente que usaremos $\ket{0}$ para referirnos a algo completamente diferente.

Centrándonos más en $\mathbb{C}^n$, el espacio vectorial complejo cuyo elementos son $n$-tuplas $(z_1, z_2, \ldots z_n)$, usaremos a veces la notación de vector columna:
$$\begin{bmatrix}
z_1 \\ z_2 \\ \vdots \\ z_n
\end{bmatrix}$$

\subsection{Bases y dimensión}

\begin{deff} Sea $\ket{v_1},\ket{v_2}, \ldots, \ket{v_n}$ vectores de un cierto espacio vectorial $\mathbb{V}$ sobre $\mathbb{C}$. Diremos que un vector $\ket{v}\in\mathbb{V}$ es \textbf{combinación lineal} de ellos si existen $a_1, a_2, \ldots, a_n \in \mathbb{C}$ escalares tal que podemos escribir $\ket{v}$ como:
\begin{equation}
\ket{v} = \sum_{i=1}^n a_i \cdot \ket{v_i}
\end{equation}
\end{deff}

\begin{deff} Sea $\{ \ket{v_1},\ket{v_2}, \ldots, \ket{v_n} \}$ un conjunto de vectores de un cierto espacio vectorial $\mathbb{V}$ sobre $\mathbb{C}$. Diremos que son \textbf{linealmente dependientes} si existen $a_1, a_2, \ldots, a_n \in \mathbb{C}$, con algún $a_i \neq 0$, tal que
\begin{equation}
a_1\ket{v_1} + a_2\ket{v_2} + \ldots + a_n\ket{v_n} = 0
\end{equation}

Además diremos que son \textbf{linealmente independientes} si no son linealmente dependientes. Es decir, si existe una combinación lineal de ellos, entonces los coeficientes son todos nulos.
\end{deff}

\begin{deff} Llamaremos entonces al conjunto $B = \{ \ket{v_1},\ket{v_2}, \ldots, \ket{v_n} \}$ \textbf{base} del espacio $\mathbb{V}$ si:
\begin{itemize}
\item $B$ es linealmente independiente.

\item $\forall \ket{v} \in \mathbb{V}$, $\ket{v}$ puede ser escrito como combinación lineal de vectores de $B$.
\end{itemize}
\end{deff}

Además podemos asegurar la existencia de este conjunto para todo espacio vectorial. Y también de que el número de elementos de dos bases distintas del mismo espacio vectorial coincide y nos referiremos a este número como \textbf{dimensión} del espacio $\mathbb{V}$.

Como hemos hecho mención antes, nuestro interés se halla en espacios vectoriales de dimensión finita, por tanto haremos omiso de las cuestiones relacionadas con espacios de dimensión infinita.

\subsection{Aplicaciones lineales y forma matricial}

\begin{deff} Una aplicación lineal entre dos espacios vectoriales $\mathbb{V}$ y $\mathbb{W}$ sobre el mismo cuerpo $\mathbb{C}$ es una aplicación $f: \mathbb{V} \longrightarrow \mathbb{W}$ tal que es lineal sobre sus componentes, es decir, si $\ket{v} = \sum_{i=1}^n a_i \cdot \ket{v_i}$ entonces se cumple:
\begin{equation} \label{eq7}
f(\ket{v}) = f(\sum_{i=1}^n a_i \cdot \ket{v_i}) = \sum_{i=1}^n a_i \cdot f(\ket{v_i})
\end{equation}

Diremos además que una aplicación lineal está definida sobre $\mathbb{V}$ para referirnos a que es una aplicación lineal de $\mathbb{V}$ a $\mathbb{V}$
\end{deff}

Un aplicación de gran importancia es la aplicación identidad, que denotaremos con $id_{\mathbb{V}}$ y cumple la propiedad de que $\forall \ket{v}\in\mathbb{V}$, $id_{\mathbb{V}}(\ket{v}) = \ket{v}$.

Observando la expresión \ref{eq7} podemos llegar a la conclusión de que una aplicación lineal está completamente determinada por su acción sobre los elementos de una base, pues todo vector se puede expresar como combinación lineal de los vectores de una base.

Una manera muy útil de expresar una aplicación lineal es a través de su expresión matricial. Veamos esto con la aplicación de $f:\mathbb{V} \longrightarrow \mathbb{W}$ sobre los vectores de las bases correspondientes. Sea $\{ \ket{v_1}, \ldots, \ket{v_m} \}$ y $\{ \ket{w_1}, \ldots, \ket{w_n} \}$ bases correspondientes a $\mathbb{V}$ y $\mathbb{W}$.

Entonces para cada j de $1$ a $m$ existirán $a_{1j}, \ldots, a_{nj} \in \mathbb{C}$ tal que
\begin{equation} \label{eq8}
f(\ket{v_j}) = \sum_{i=1}^n a_{ij} \ket{w_i}
\end{equation}
por ser $f(\ket{v_j}) \in \mathbb{W}$ y $\{ \ket{w_1}, \ldots, \ket{w_n} \}$ base de $\mathbb{W}$.

\begin{deff}Llamaremos entonces $A$ a la matriz formada por los elementos $a_{ij}$ de la ecuación \ref{eq8} en la posición $(ij)$ en la matriz, como representación matricial de la función $f$.
\end{deff}

Además, tomando las \textbf{coordenadas} $\boldsymbol{z_j}$ de un vector $\ket{v} = \sum_{j=1}^m \boldsymbol{z_j} \ket{v_j}$ de $\mathbb{V}$ y su imagen por $f$ con la expresión \ref{eq8}:
\begin{equation}
f(\ket{v}) = f(\sum_{j=1}^m z_j \ket{v_j}) = \sum_{j=1}^m z_j f(\ket{v_j}) = \sum_{j=1}^m z_j (\sum_{i=1}^n a_{ij} \ket{w_i}) = 
\sum_{i=1}^n (\sum_{j=1}^m a_{ij} z_{j}) \ket{w_i}
\end{equation}
podemos observar la aplicación de $f$ sobre el vector $\ket{v}$ no es más que el producto de la matriz $A$ con el vector $\ket{v}$ en columnas:
\begin{equation}
A\ket{v} = 
\begin{bmatrix}
a_{11} & a_{12} &\ldots & a_{1m} \\
a_{21} & a_{22} &\ldots & a_{2m} \\
\vdots & \vdots &\ddots & \vdots \\
a_{n1} & a_{n2} &\ldots & a_{nm}
\end{bmatrix}
\begin{bmatrix}
z_1 \\ z_2 \\ \vdots \\ z_m
\end{bmatrix} =
\begin{bmatrix}
\sum_{j=1}^m a_{1j}z_j \\
\sum_{j=1}^m a_{2j}z_j \\
\vdots \\
\sum_{j=1}^m a_{nj}z_j \\
\end{bmatrix}
\end{equation}

\subsection{Producto Escalar y Espacios de Hilbert}
%Intro de producto escalar (???)

\begin{deff}Un \textbf{producto escalar}, o también conocido como producto interno, es una aplicación $(\cdot, \cdot): \mathbb{V}\times\mathbb{V} \longrightarrow \mathbb{C}$ que cumple:
\begin{itemize}

\item Es definida positiva,
\begin{equation}
(\ket{v}, \ket{v}) \geq 0
\end{equation} y
\begin{equation}
(\ket{v}, \ket{v}) = 0 \Leftrightarrow \ket{v} = 0
\end{equation}

\item Es lineal en el primer argumento y lineal conjugada en el segundo,
\begin{equation}
(a\ket{u} + b\ket{v}, \ket{w}) = \bar{a} \cdot(\ket{u}, \ket{w}) + \bar{b} \cdot(\ket{v}, \ket{w})
\end{equation}
\begin{equation}
(\ket{u}, a\ket{v} + b\ket{w}) = a \cdot (\ket{u}, \ket{v}) + b \cdot (\ket{u}, \ket{w})
\end{equation}

\item Es anti-simétrico,
\begin{equation}
(\ket{u}, \ket{v}) = \overline{(\ket{v}, \ket{u})}
\end{equation}
\end{itemize}
donde $a,b \in \mathbb{C}$, $\ket{u}, \ket{v}, \ket{w} \in \mathbb{V}$ y $\bar{a} \in \mathbb{C}$ es el conjugado complejo del elemento $a$.
\end{deff}
La notación estándar del producto escalar en mecánica cuántica no es $(\ket{u}, \ket{v})$, sino $\braket{u|v}$, donde $\ket{u}$ y $\ket{v}$ son vectores de $\mathbb{V}$ y $\bra{u}$ denota el vector dual al vector $\ket{u}$, también conocido como \textbf{bra}. El dual es una aplicación lineal cuya definición es $\bra{u}(\ket{v}) := \braket{u|v} = (\ket{u},\ket{v})$. A partir de ahora, usaremos más esta notación.

\begin{deff}Diremos que dos vectores $\ket{u}$ y $\ket{v}$ son \textbf{ortogonales} si su producto escalar es 0.

Además definiremos como \textbf{norma} del vector como 
\begin{equation}
\norm{\ket{v}} = \sqrt{\braket{v|v}}
\end{equation}
y diremos que $\ket{v}$ es unitario o normalizado si $\norm{\ket{v}} = 1$.
\end{deff}

\begin{deff}Por tanto diremos que un conjunto, $\ket{i} \in \mathbb{V}$ de vectores es \textbf{ortonormal} si son vectores unitarios y además son ortogonales entre sí. Es decir,
\begin{equation}
\forall \ket{i},\ket{j} \in \mathbb{V} \:
\braket{i|j} = \delta_{ij} = \left\{ 
\begin{array}{lcc}
1 & si & i = j \\
0 & si & i \neq j
\end{array} \right.
\end{equation}
\end{deff}

Un espacio vectorial euclídeo no es más que un espacio vectorial dotado de un producto escalar. Trabajaremos a partir de ahora en un espacio vectorial complejo de dimensión finita y con un producto escalar. Dicho espacio es denominado usualmente como \textbf{espacio de Hilbert}.

\begin{deff}\textbf{Espacio de Hilbert}
(falta)(y buscar referencia)
\end{deff}

En nuestro caso por la finitud de la dimensión, un espacio de Hilbert es equivalente a espacio euclídeo.
No entraremos en detalles en el caso de que la dimensión sea infinita, ya que para hablar de espacio de Hilbert sería necesario que se cumplan alguna propiedad extra. Nos centraremos en el caso de la dimensión finita cuando hablemos de espacio de Hilbert.

Podemos ver ahora que el producto escalar en un espacio de Hilbert tiene una representación matricial muy útil.
Consideramos $\ket{u} = \sum_i u_i\ket{i}$ y $\ket{v} = \sum_j v_j\ket{j}$ con $\ket{i}, \ket{j}$ vectores de una base ortonormal $\{ \ket{1}, \ket{2}, \ldots, \ket{n} \}$.
Entonces el producto escalar,
\begin{equation}
\braket{u|v} = (\sum_i u_i\ket{i}, \sum_j v_j\ket{j}) = \sum_{ij} \bar{u_i} v_j\braket{i|j} = \sum_{ij} \bar{u_i} v_j\delta_{ij} = \sum_i \bar{u_i} v_i
\end{equation}
que claramente es el producto entre un vector fila conjugado y uno columna,
\begin{equation}
\braket{u|v} =
\left[ \bar{u_1}  \bar{u_2}  \ldots  \bar{u_n} \right]
\begin{bmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{bmatrix} =
\sum_i \bar{u_i} v_i
\end{equation}

Podemos observar también que el vector dual $\bra{u}$ se puede expresar como un vector fila cuyas componentes están conjugadas.

Una manera útil de ver las aplicaciones lineales es a través de su representación como \textbf{producto exterior}.

\begin{deff}Llamaremos producto exterior a la aplicación $\ket{u}\bra{v}: \mathbb{V} \longrightarrow \mathbb{W}$, donde $\ket{v} \in \mathbb{V}$ y $\ket{u} \in \mathbb{W}$,
\begin{equation}
\ket{u}\bra{v}(\ket{v'}) = \ket{u}\braket{v|v'} = \braket{v|v'} \cdot \ket{u}
\end{equation}
\end{deff}

Considerando ahora una base ortonormal $\{\ket{i}\}_{1\leq i\leq n}$, podemos deducir la propiedad de completitud del producto exterior. Sea el vector $\ket{v} = \sum_i v_i\ket{i}$, teniendo en cuenta que $\braket{i|v} = v_i$, tenemos que la aplicación de $\sum_i \ket{i}\bra{i}$ sobre el vector
\begin{equation}
(\sum_i \ket{i}\bra{i}) (\ket{v}) = \sum_i \ket{i}\braket{i|v} = \sum_i v_i \ket{i} = \ket{v}
\end{equation}
Lo que nos permite llegar a la conclusión de que $\sum_i \ket{i}\bra{i}$ es equivalente a la identidad.

%Esta parte necesita una revisión
Teniendo en mente esta propiedad podemos conseguir la expresión de un aplicación lineal $f: \mathbb{V} \longrightarrow \mathbb{W}$, considerando $\ket{v_i}$ y $\ket{w_j}$ un base ortonormal de ambos espacios. Con la propiedad de completitud tenemos que
\begin{equation}
f \equiv id_{\mathbb{W}} \circ f \circ id_{\mathbb{V}} \equiv
\sum_{ij} (\ket{w_j}\bra{w_j}) \circ f \circ (\ket{v_i}\bra{v_i}) \equiv \sum_{ij} \braket{w_j|f(v_i)} \ket{w_j}\bra{v_i}
\end{equation}
donde podemos concluir que el valor $\braket{w_j|f(v_i)}$ es el elemento de la columna $i$ y fila $j$ de la representación matricial de $f$ en las bases correspondientes.

Además observamos que esto concuerda con la expresión de un vector y su dual como vector fila y columna pues el producto resultante de
\begin{equation}
\begin{bmatrix}
w_1 \\ \vdots \\ w_n
\end{bmatrix}
\left[ v_1 \ldots v_n \right]
= \begin{bmatrix}
w_1 v_1 & \ldots & w_1 v_n \\
\vdots & \ddots & \vdots \\
w_n v_1 & \ldots & w_n v_n
\end{bmatrix}
\end{equation} es una matriz, correspondiente a la aplicación lineal.

\subsection{Matrices Adjuntas o Hermitianas}
Veremos ahora un tipo de matriz y su función asociada que se comporta de una manera muy buena con el espacio de Hilbert.

\begin{deff}Consideramos una matriz $A \in \mathbb{C}^{n\times n}$, definiremos su \textbf{adjunta} o \textbf{conjugada Hermitiana} como la matriz traspuesta con los elementos conjugados y lo denotaremos como $A^\dagger = \overline{A^T}$

Además diremos que $A$ es \textbf{hermintiana} si $A^\dagger = A$ y llamaremos a la aplicación lineal asociada, aplicación \textbf{auto-adjunta}.

\end{deff}

Podemos ver fácilmente que este tipo de matrices cumplen ciertas propiedades,
\begin{itemize}

\item $\forall \ket{u}, \ket{v} \in \mathbb{V}$
\begin{equation}
(\ket{u}, A \ket{w}) = (A^\dagger \ket{u},\ket{w})
\end{equation}

\item Definiremos por convenio la adjunta de un vector $\ket{v}^\dagger = \bra{v}$, que concuerda con toda la notación que hemos estado usando. De esta manera, teniendo en cuenta que $(AB)^\dagger = B^\dagger A^\dagger$, tenemos que
\begin{equation}
(A\ket{v})^\dagger = \bra{v}A^\dagger
\end{equation}
\end{itemize}
%alguna propiedad más(???)

Otras matrices que nos interesan son las matrices \textbf{unitarias}. Son un tipo de matrices invertibles que cumplen que
\begin{equation}
U * U^\dagger = U^\dagger * U = I_n
\end{equation}

\subsection{Producto Tensorial}

En esta sección estudiaremos el producto tensorial entre espacios vectoriales, una herramienta esencial para trabajar con sistemas cuánticos de varios elementos en esta área. Hablaremos de estos sistemas en secciones posteriores, por ahora nos centraremos en el producto tensorial.

\begin{deff}
Consideramos $\mathbb{V}$ y $\mathbb{W}$ dos espacios vectoriales, llamaremos \textbf{producto escalar} a la aplicación \underline{bilineal} $\otimes : \mathbb{V}\times \mathbb{W} \longrightarrow \mathbb{V}\otimes \mathbb{W}$, que lleva $\ket{v} \in \mathbb{V}$ y $\ket{w} \in \mathbb{W}$ a un elemento de $\mathbb{V} \otimes \mathbb{W}$ que llamaremos \textbf{tensor} y lo denotaremos por $\ket{v}\otimes \ket{w}$, o de manera abreviada $\ket{v}\ket{w}$, $\ket{vw}$.
\end{deff}
Además esta aplicación cumple las siguientes propiedades:
\begin{itemize}
\item Sea $z$ un escalar y $\ket{v}$ y $\ket{w}$ elementos de $\mathbb{V}$ y $\mathbb{W}$ respectivamente,
\begin{equation}
z(\ket{v}\otimes\ket{w}) = (z\ket{v})\otimes\ket{w} = \ket{v}\otimes(z\ket{w})
\end{equation}

\item Para $\ket{v_1}$, $\ket{v_2} \in \mathbb{V}$ y $\ket{w} \in \mathbb{W}$ se tiene,
\begin{equation}
(\ket{v_1} + \ket{v_2}) \otimes \ket{w} = \ket{v_1}\otimes\ket{w} + \ket{v_2}\otimes\ket{w}
\end{equation}

\item Para $\ket{v} \in \mathbb{V}$ y $\ket{w_1}$, $\ket{w_2} \in \mathbb{W}$ se tiene,
\begin{equation}
(\ket{v}\otimes (\ket{w_1} +  \ket{w_2}) = \ket{v}\otimes\ket{w_1} + \ket{v}\otimes\ket{w_2}
\end{equation}

\end{itemize}

El espacio de la imagen sigue siendo un espacio vectorial y de hecho, si tomamos $\lbrace \ket{v_1}, \ldots, \ket{v_m} \rbrace$ y $\lbrace \ket{w_1}, \ldots, \ket{w_n} \rbrace$ como bases de $\mathbb{V}$ y $\mathbb{W}$ respectivamente, tenemos que
\begin{equation}
\lbrace \ket{v_i}\otimes\ket{w_j} \mid 1\leq i \leq m, 1\leq j \leq n \rbrace
\end{equation}
es una base de $\mathbb{V}\otimes\mathbb{W}$. Y por tanto, la dimensión como espacio vectorial de $\mathbb{V}\otimes\mathbb{W}$ es $m\cdot n$ siendo $m$ y $n$ la dimensión de $\mathbb{V}$ y $\mathbb{W}$ respectivamente.

Las aplicaciones lineales del espacio $\mathbb{V}\otimes\mathbb{W}$ que consideraremos serán aquellas resultantes del producto tensorial de dos aplicaciones lineales del espacio de los factores, de manera que cumplan
\begin{equation} \label{prtensorial_aplineal}
(f\otimes g) (\ket{v}\otimes\ket{w}) = f(\ket{v}) \otimes g(\ket{w}).
\end{equation}

De hecho, toda aplicación lineal de $\mathbb{V}\otimes\mathbb{W}$ se puede representar como combinación lineal de aplicaciones de $\mathbb{V}$ y $\mathbb{W}$ con el producto tensorial, actuando como espacio resultante del producto tensorial del espacio de los endomorfismos.

En cuanto a la práctica resulta muy cómodo trabajar con la representación matricial de estas aplicaciones y el producto de Kronecker. Pues si consideramos $A$ una matriz $m\times n$ y $B$ una matriz $p\times q$, su producto tensorial sería:
\begin{equation}
A\otimes B =
\begin{bmatrix}
a_{11}B & a_{12}B & \ldots & a_{1n}B \\
a_{21}B & a_{22}B & \ldots & a_{2n}B \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1}B & a_{m2}B & \ldots & a_{mn}B \\
\end{bmatrix}
\end{equation}
donde $a_{ij}$ es el elemento de la posición $(ij)$ de la matriz A.

De la misma manera se puede operar con los vectores columnas del espacio vectorial $\mathbb{C}^n$. Por ejemplo, si tenemos $\ket{v} y \ket{w}$ vectores de $\mathbb{C}^n$ y $v_1, v_2, \ldots, v_n$, $w_1, w_2, \ldots, w_n$ sus coordenadas respectivamente en una base. Entonces su producto tensorial en forma matricial sería,
\begin{equation}
\begin{bmatrix}
	v_1 \\ v_2 \\ \vdots \\ v_n
\end{bmatrix} \otimes
\begin{bmatrix}
	w_1 \\ w_2 \\ \vdots \\ w_n
\end{bmatrix} =
\begin{bmatrix}
	v_1 \cdot \begin{bmatrix}
		w_1 \\ w_2 \\ \vdots \\ w_n
	\end{bmatrix} \\
	v_2 \cdot \begin{bmatrix}
		w_1 \\ w_2 \\ \vdots \\ w_n
	\end{bmatrix} \\
	\vdots \\
	v_n \cdot \begin{bmatrix}
		w_1 \\ w_2 \\ \vdots \\ w_n
	\end{bmatrix}
\end{bmatrix} =
\begin{bmatrix}
v_1w_1 \\ v_1w_2 \\ \vdots \\ v_1w_n \\
v_2w_1 \\ v_2w_2 \\ \vdots \\ v_2w_n \\
v_nw_1 \\ v_nw_2 \\ \vdots \\ v_nw_n
\end{bmatrix}
\end{equation}

%Aplicaciones lineales y matrices[x]

%Bases[x]

%Producto escalar[x]

%Autovalores y autovectores puede ser.[Por ahora no]

%Matrices Adjuntas o Hermitian(buscar traducción)

%Producto tensorial

\newpage

\section{Estructuras y Puertas Cuánticas}

En esta sección veremos el sistema de información en el que se basa la computación cuántica y su representación matemática. Igual que en la computación clásica se basa en el concepto de bit, en la computación cuántica se estudiará el \textbf{bit cuántico} o \textbf{qubit} (de quantum bit en inglés). Es verdad que el qubit, al igual que el bit, son objetos físicos de un sistema físico real como partículas subatómicas en un ordenador cuántico. Pero nosotros nos centraremos en describir el qubit como un objeto matemático abstracto con ciertas propiedades determinadas.


\subsection{Qubit}

Conocemos el concepto de bit, que es un elemento de un sistema con dos estados posibles. Estos dos estados son generalmente denominados como "verdadero" o "falso, o incluso con $0$ o $1$.
\begin{deff}Entonces llamaremos \textbf{qubit} al objeto matemático con dos posibles estados correspondientes al bit clásico $\ket{0}$ y $\ket{1}$, además de una combinación lineal de estos dos estados que llamaremos como \textbf{superposición}:
\begin{equation}
\ket{\varphi} = \alpha\ket{0} + \beta\ket{1}
\end{equation}
Con $\alpha$ y $\beta$ números complejos que cumplen que $|\alpha|^2 + |\beta|^2 = 1$.
\end{deff}
Se entiende fácilmente el estado de un qubit como un vector del espacio vectorial complejo de dimensión 2, restringido a la circunferencia unidad, donde los estados $\ket{0}$ y $\ket{1}$ son los elementos de la base ortonormal del espacio con $\alpha$ y $\beta$ como coordenadas del vector de norma 1.
\begin{figure}[h]
	\centering
	\includegraphics[scale=.3]{qubit_vector}
\end{figure}

Podemos determinar el estado de un bit clásico a la hora de examinarlo, pero en el caso del qubit, no podemos determinar el estado cuántico de un qubit en superposición, es decir, no podemos hallar el valor de $\alpha$ y $\beta$. Lo que sí podemos hacer es \textbf{medir} el qubit, determinar si colapsa en el estado $\ket{0}$ con probabilidad $|\alpha|^2$ ó en el estado $\ket{1}$ con probabilidad $|\beta|^2$. En otra palabras, el proceso de medir un qubit, nos devuelve como salida un estado clásico al que colapsa y deja de estar en superposición de varios estados de manera simultanea.

Veamos ahora otra representación geométrica del qubit que puede resultar útil. Consideramos un qubit en estado de superposición.
\begin{equation}
\ket{\psi} = c_0\ket{0} + c_1\ket{1} 
\end{equation}
con $\|c_0|^2 + |c_1|^2 = 1$. Reescribimos la expresión en coordenadas en forma exponencial de un número complejo,
\begin{equation}
\ket{\psi} = r_0 e^{i\varphi_0}\ket{0} + r_1 e^{i\varphi_1}\ket{1}
\end{equation}
Lo multiplicamos por un escalar de módulo 1, así no alteramos su estado cuántico,
\begin{equation}
e^{-i\varphi_0}\ket{\psi} = e^{-i\varphi_0}(r_0 e^{i\varphi_0}\ket{0} + r_1 e^{i\varphi_1}\ket{1}) = 
r_0\ket{0} + r_1 e^{i(\varphi_1 - \varphi_0)}\ket{1}
\end{equation}
Tomando ahora coordenadas polares $r_0 = \cos(\theta)$, $r_1 = \sin(\theta)$ y el cambio de variables $\varphi = \varphi_1 - \varphi_0$, resulta en la siguiente expresión,
\begin{equation}
\ket{\psi} = \cos(\theta)\ket{0} + e^{i\varphi}\sin(\theta)\ket{1}
\end{equation}
Considerando $\theta$ y $\varphi$ como coordenadas de un punto en una esfera tridimensional, podemos ver el estado del qubit como un punto en la superficie de dicha esfera, siendo los polos los estados $\ket{0}$ y $\ket{1}$. Esta esfera recibe el nombre de \textbf{esfera de Bloch} y veremos en poco que con ella podemos representar operaciones de qubits como rotaciones de la esfera.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.3]{esfera_bloch}
	\caption{Esfera de Bloch.}
\end{figure}


\subsection{Sistema de Varios Qubits}

Tomamos interés en un sistema de un número mayor de qubits, que enlazaremos a través del producto tensorial de los espacios vectoriales. Por tanto un elemento de él estará representado por un vector de $\mathbb{C}^2 \otimes \mathbb{C}^2 \otimes \ldots \otimes \mathbb{C}^2$ que denotaremos como $(\mathbb{C}^2)^{\otimes n}$ donde $n$ es el número de qubits del sistema y cuya dimensión como espacio vectorial es $2^n$

Por ejemplo, si queremos un sistema de 2 qubits en comparación a los estados clásicos de un bit tendríamos 00, 01, 10 y 11, por tanto nuestro sistema de 2 qubits tendría los estados $\ket{00}$, $\ket{01}$, $\ket{10}$ y $\ket{11}$ que se corresponden con el producto tensorial del estado de los dos qubits $\ket{x}\otimes\ket{y}$ con $x$, $y\in \lbrace 0, 1\rbrace$.
Vamos a trabajar más cómodamente con coordenadas del vector en su expresión matricial, consideramos primero,
\begin{equation}
\ket{0} = \begin{bmatrix}
	1 \\ 0
\end{bmatrix}, \ 
\ket{1} = \begin{bmatrix}
	0 \\ 1
\end{bmatrix}
\end{equation}
Como hemos visto en la sección anterior, aplicaremos el producto de  Kroner para obtener las expresiones matriciales de $\ket{00}$, $\ket{01}$, $\ket{10}$ y $\ket{11}$,
\begin{equation}
\ket{00} =
\begin{bmatrix}
	1 \\ 0 \\ 0 \\ 0
\end{bmatrix}, \ 
\ket{01} =
\begin{bmatrix}
	0 \\ 1 \\ 0 \\ 0
\end{bmatrix}, \ 
\ket{10} =
\begin{bmatrix}
	0 \\ 0 \\ 1 \\ 0
\end{bmatrix}, \ 
\ket{11} =
\begin{bmatrix}
	0 \\ 0 \\ 0 \\ 1
\end{bmatrix}
\end{equation}
Observamos que forman una base ortonormal de un espacio vectorial de dimensión $2^2 = 4$ y que además cada coordenada corresponde a un estado clásico del qubit:
\begin{equation}
\ket{01} =
\begin{matrix}
	\textbf{00} \\ \textbf{01} \\ \textbf{10} \\ \textbf{11}
\end{matrix}
\begin{bmatrix}
	0 \\ 1 \\ 0 \\ 0
\end{bmatrix}
\end{equation}
Por tanto, si tomamos un sistema de dos qubits arbitrario en superposición,
\begin{equation}
\ket{\psi} = c_0 \ket{00} + c_1 \ket{01} + c_2 \ket{10} + c_3 \ket{11}
\end{equation}
su representación matricial sería:
\begin{equation}
\ket{\psi} =
\begin{matrix}
	\textbf{00} \\ \textbf{01} \\ \textbf{10} \\ \textbf{11}
\end{matrix}
\begin{bmatrix}
	c_0 \\ c_1 \\ c_2 \\ c_3
\end{bmatrix}
\end{equation}
Trabajaremos a partir de ahora con la notación del sistema de varios qubits como $\ket{xy}$, $\ket{x\otimes y}$, ó $\ket{x}\otimes\ket{y}$ y los trataremos de manera indiferente según convenga.

Podemos medir únicamente un subconjunto de qubits del sistema total siendo la probabilidad de obtener el qubit en un estado concreto la suma de las probabilidades del estado del sistema con el qubit correspondiente en el estado en concreto. Por ejemplo si tomamos el sistema de dos qubits anterior, la probabilidad de que el primer qubit esté en el estado $\ket{0}$ será $|c_0|^2 + |c_1|^2$ que son las probabilidades de que el sistema esté en el estado $\ket{00}$ ó $\ket{01}$. Hacemos notar que tras medirlo, el sistema quedará en el estado
\begin{equation}
\ket{\psi'} = \frac{c_0\ket{00} + c_1\ket{01}}{\sqrt{|c_0|^2 + |c_1|^2}}
\end{equation}
ya que hemos determinado el estado del primer qubit haciéndolo colapsar a un estado clásico a la hora de medirlo. Además, el denominador $\sqrt{|c_0|^2 + |c_1|^2}$ se debe por normalizar el vector que representa el estado del sistema. Recordemos que esto era una condición necesaria que tenemos que pedir.
Un ejemplo importante de un sistema de dos qubits es el \textbf{estado de Bell} ó \textbf{par ERP},
\begin{equation}
\frac{\ket{00} + \ket{11}}{\sqrt{2}}
\end{equation}
que nos muestra una propiedad importante de los sistemas de varios qubits a la hora de hacer mediciones. Si medimos el primer qubit tendrá una probabilidad de $(\frac{1}{\sqrt{2}})^2 = \frac{1}{2}$ de estar en el estado $\ket{0}$ y una probabilidad de $\frac{1}{2}$ de estar en el estado $\ket{1}$. Esto dejará el sistema en el estado $\ket{\psi'} = \ket{00}$ ó $\ket{\psi'} = \ket{11}$. En cualquier caso tenemos que ambas situaciones, tras medir el primer qubit, si medimos el segundo este coincidirá con el primero. Es decir, que ambos qubits está relacionados(entagled).

Nos fijamos un momento en la dimensión del espacio vectorial que representa nuestro sistema. Supongamos que tenemos un número de un tamaño considerable de qubits, $n=500$. Si quisiéramos simular este sistema en un ordenador clásico realizando las operaciones matriciales necesarias en la computación, tendríamos que para un estado del sistema almacenar $2^{500}$ coordenadas complejas del vector además de trabajar con matrices de tamaño $2^{500}$. Esto claramente no es factible hoy en día resultando en una de los problemas en cuanto a la computación cuántica.

\subsection{Circuitos y Puertas Cuánticas}

Al igual que un circuito de un ordenador clásico consiste en cables y puertas lógicas que interaccionan con la información que es transportada por el cableado, un circuito cuántico consiste en cables que transportan información cuántica en forma de qubits que son manipulados a través de puertas cuánticas.

Consideremos primero la puerta clásica \textbf{NOT} que queremos que realice la operación de la tabla de verdad sobre un bit, es decir,
\begin{equation}
\begin{cases}
0 \rightarrow 1 \\
1 \rightarrow 0
\end{cases}
\end{equation}
intercambiando los estados 0 y 1. Queremos que nuestra puerta cuántica se comporte de la misma manera sobre qubits. Queremos que intercambie los estados $\ket{0}$ y $\ket{1}$ y además por ser puerta cuántica pediremos que sea lineal, es decir, si tenemos un un qubit arbitrario en estado de superposición
\begin{equation}
\alpha\ket{0} + \beta\ket{1}
\end{equation}
queremos que se aplique de forma lineal a cada uno de los términos de la suma,
\begin{equation}
\alpha\ket{1} + \beta\ket{0}.
\end{equation}
Igual que hemos asociado con vectores a los bits, y podemos operar con los vectores de forma matricial, las puertas lógicas están asociados a las matrices.
Por tanto si tomamos la matriz $\textrm{NOT} = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}$, esta matriz cumple que
\begin{equation}
\begin{bmatrix}
0 & 1 \\
1 & 0
\end{bmatrix}
\begin{bmatrix}
1 \\ 0
\end{bmatrix} =
\begin{bmatrix}
0 \\ 1
\end{bmatrix}
\textrm{ y }
\begin{bmatrix}
0 & 1 \\
1 & 0
\end{bmatrix}
\begin{bmatrix}
0 \\ 1
\end{bmatrix} =
\begin{bmatrix}
1 \\ 0
\end{bmatrix}
\end{equation}
tomando el vector correspondiente al estado cuántico $\ket{0}$ y $\ket{1}$ y los intercambia:
\begin{equation}
\textrm{NOT} \ket{0} = \ket{1} \textrm{ y } \textrm{NOT}\ket{1} = \ket{0}
\end{equation}
Otra propiedad que les pediremos a las puertas cuánticas es que sean reversibles. Esto es que dados la salida y la operación aplicada seamos capaces de determinar la entrada del circuito. Representaremos las puertas cuánticas con matrices unitarias que son reversibles por su propia adjunta. Recordemos que esto es:
\begin{equation}
U * U^\dagger = U^\dagger * U = I_n
\end{equation}
Podemos poner de ejemplo, la operación AND, que toma dos bits y nos devuelve 1 si ambos inputs son 1. Esta operación no es reversible, ya que si conocemos solamente el output, no podemos determinar cuál ha sido el input de la operación. \\
De esta manera tenemos que, aparte de la propiedad de ser lineal que está implicada, cualquier matriz unitaria lleva asociada su puerta cuántica correspondiente, siendo el único requisito que pediremos.
Veamos otras puertas cuánticas de un qubits de importancia. Si consideramos las matrices de Pauli,
\begin{equation}
X = \begin{bmatrix}
	0 & 1 \\
	1 & 0
\end{bmatrix}, \ 
Y = \begin{bmatrix}
	0 & -i \\
	i & 0
\end{bmatrix}, \ 
Z = \begin{bmatrix}
	1 & 0 \\
	0 & -1
\end{bmatrix},
\end{equation}
tendremos que cada una de ellas tiene asociado una puerta cuántica correspondiente. De hecho, la matriz X corresponde con la puerta NOT. Podemos evaluar la matriz con los estados del qubit para determinar su comportamiento, pues por ejemplo si tomamos la matriz Z,
\begin{equation}
Z(\alpha\ket{0} + \beta\ket{1}) = 
\begin{bmatrix}
	1 & 0 \\
	0 & -1 
\end{bmatrix}
\begin{bmatrix}
	\alpha \\ \beta
\end{bmatrix} =
\begin{bmatrix}
	\alpha \\ -\beta
\end{bmatrix} =
\alpha\ket{0} - \beta\ket{1},
\end{equation}
que cambia el signo del coeficiente de $\ket{1}$.\\
Otra manera de visualizar estas puertas es como rotaciones de $180º$ sobre la esfera de Bloch en el eje correspondiente. \\
\begin{figure}[h]
	\centering
	\includegraphics[scale=.65]{rotacion_bloch}
	\caption{Rotación sobre el eje Y en la esfera de Bloch.}
\end{figure}

Una puerta cuántica de mucha importancia es la puerta de Hadamard ya que nos permitirá poner qubit en una configuración en la que todos los estados son equiprobables. Esta puerta tiene por matriz:
\begin{equation}
\frac{1}{\sqrt{2}}
\begin{bmatrix}
1 & 1 \\
1 & -1
\end{bmatrix},
\end{equation}
que lleva
\begin{equation}
\begin{cases}
\ket{0} \rightarrow \frac{1}{\sqrt{2}}(\ket{0} + \ket{1}) \\
\ket{1} \rightarrow \frac{1}{\sqrt{2}}(\ket{0} - \ket{1})
\end{cases}
\end{equation}
Una propiedad que cumple $H^2 = I$ que se comprueba fácilmente. Esto nos permite posteriormente llevar estados $\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})$ a $\ket{0}$, lo que usaremos posteriormente en los algoritmos.

Ya hemos mencionado que es posible visualizar las puertas cuánticas como rotaciones en la esfera de Bloch, por ejemplo si tomamos la expresión de un estado de un qubit en polares,
\begin{equation}
\ket{\psi} = \cos(\theta)\ket{0} + e^{i\varphi}\sin(\theta)\ket{1},
\end{equation}
y le aplicamos la siguiente matriz
\begin{equation}
R(\omega) = \begin{bmatrix}
	1 & 0 \\
	0 & e^\omega
\end{bmatrix} 
\end{equation}
obteniendo como resultado:
\begin{equation}
\ket{\psi'} = \cos(\theta)\ket{0} + e^\omega e^{i\varphi}\sin(\theta)\ket{1} = \cos(\theta)ket{0} + e^{i\varphi + \omega}\sin(\theta)\ket{1}
\end{equation}
de esta manera hemos conseguido rotar la esfera alrededor del eje Z, por lo que no hemos variado lo que podemos considerar como latitud, sino hemos variado su longitud. Este tipo de operaciones se denominan \textbf{cambios de fase}, ya que sólo estamos alterando el valor del parámetro $e^{i\varphi}$. Observamos que esta alteración de la fase del estado del qubit no produce cambios en cuanto a la medición del mismo, ya que la probabilidad de que un qubit colapse en un estado clásico depende en este caso únicamente del parámetro $\theta$, su latitud en la esfera de Bloch.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.65]{rotacion_fase}
\end{figure}
Otras rotaciones, por ejemplos si queremos rotar la espera un cierto ángulo $\omega$ respecto a un eje, tendría la siguiente expresión:
\begin{equation}
\begin{cases}
R_x(\omega) = \cos(\frac{\omega}{2})I -i\sin(\frac{\omega}{2})X =
\begin{bmatrix}
cos(\frac{\omega}{2}) & -i\sin(\frac{\omega}{2}) \\
-i\sin(\frac{\omega}{2}) & \cos(\frac{\omega}{2})
\end{bmatrix} \\
R_y(\omega) = \cos(\frac{\omega}{2})I -i\sin(\frac{\omega}{2})Y =
\begin{bmatrix}
	cos(\frac{\omega}{2}) & -\sin(\frac{\omega}{2}) \\
	\sin(\frac{\omega}{2}) & \cos(\frac{\omega}{2})
\end{bmatrix} \\
R_z(\omega) = \cos(\frac{\omega}{2})I -i\sin(\frac{\omega}{2})Z =
\begin{bmatrix}
	e^{-i\omega/2} & 0 \\
	0 & e^{i\omega/2}
\end{bmatrix}
\end{cases}
\end{equation}
También podemos realizar rotaciones respecto de un vector dado, consideramos $D = (D_x, D_y, D_z)$ un vector arbitrario de módulo 1, con las coordenadas correspondientes. La matriz de la rotación estará determinada por la siguiente expresión:
\begin{equation}
R_D(\omega) = \cos(\frac{\omega}{2})I -i\sin(\frac{\omega}{2})(D_x X + D_y Y + D_z Z)
\end{equation}
Veamos ahora, puertas cuánticas que involucren más de un qubit, que a pesar de que no podremos representarlos ya en la esfera de Bloch, podemos seguir considerando su representación matricial.

Una de las puertas más importantes es la puerta \textbf{NOT controlada} o \textbf{CNOT}. Esta puerta tomará dos entradas y dará dos salidas. La primera entrada la llamaremos bit de control, es decir, controlará el bit de salida. Representaremos la puerta en la siguiente ilustración de un circuito cuántico, donde cada recta horizontal representa un cable que lleva el qubit siguiendo la lectura de izquierda a derecha.
\begin{figure}[h]
\centering
\scalebox{1.0}{
\Qcircuit @C=1.0em @R=0.8em @!R { \\
	 \lstick{\ket{x}} & \ctrl{1} & \qw & \rstick{\ket{x}}\\
	 \lstick{\ket{y}} & \targ & \qw  & \rstick{\ket{x\oplus y}}\\
\\ }}
\end{figure}
Si $\ket{x} = \ket{0}$, la salida del segundo bit $\ket{y}$ permanecerá igual. Si  $\ket{x} = \ket{1}$ entonces $\ket{y}$ se le aplicará la puerta NOT, es decir, será lo contrario. Es decir, realiza la siguiente transformación
\begin{equation}
\begin{cases}
\ket{00} \rightarrow \ket{00} \\
\ket{01} \rightarrow \ket{01} \\
\ket{10} \rightarrow \ket{11} \\
\ket{11} \rightarrow \ket{10}
\end{cases}
\end{equation}
Esto se puede ver como que la puerta transforma un par de bits $\ket{x, y}$ en $\ket{x, x\oplus y}$, donde $\oplus$ es la operación binaria de OR excluyente, o también como la suma en módulo 2.
También podemos describir la puerta CNOT con su representación matricial, considerando como base del espacio vectorial $\lbrace \ket{00}, \ket{01}, \ket{10}, \ket{11} \rbrace$,
\begin{equation}
\textrm{CNOT} = \begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 
\end{bmatrix}
\end{equation}
Observamos que claramente esta puerta es unitaria pues el producto por su adjunta que es ella misma resulta en la matriz identidad, pues tenemos que se cumple que $CNOT^{\dagger} CNOT = I$.
Esto también se puede entender como que la puerta CNOT es reversible por ella misma:\\
\begin{figure}[h]
\centering
\scalebox{1.0}{
\Qcircuit @C=1.0em @R=0.8em @!R { \\
	\nghost{0} & \ket{x} & \ & \ & \ & \ & \ket{x} & \ & \ & \ & \ket{x}  \\
	\nghost{1} & \qw & \qw & \qw & \ctrl{2} & \qw & \qw & \qw & \ctrl{2} & \qw & \qw & \qw \\
	\nghost{2} & \ket{y} & \ & \ & \ & \ & \ket{x\oplus y} & \ & \ & \ & \ & \ & \ket{x\oplus(x\oplus y)}  \\
	\nghost{3} & \qw & \qw & \qw & \targ & \qw & \qw & \qw & \targ & \qw & \qw & \qw \\
\\ }}
\end{figure}

El estado de entrada es $\ket{x, y}$ que queda trasformado en $\ket{x, x\oplus y}$ y esta última en $\ket{x, x\oplus (x\oplus y)}$. Esto es $\ket{x, (x\oplus x) \oplus y} = \ket{x, 0\oplus y} = \ket{x, y}$, ya que $x\oplus x = 0$.

Otra puerta reversible de mucha importancia es la de Toffoli,
que funciona de manera similar a la puerta NOT controlada. Trabaja con 3 bits de entrada y salida, en el que aplica la puerta NOT al último bit $\ket{z}$ si y solo si los dos anteriores tienen por estado 1, $\ket{x, y} = \ket{11}$. En otras palabras lleva el $\ket{x,y,z}$ a $\ket{x,y,z\oplus(x\wedge y)}$. \\
\begin{figure}[h]
\centering
\scalebox{1.0}{
\Qcircuit @C=1.0em @R=0.8em @!R { \\
	 \lstick{\ket{x}} & \ctrl{1} & \qw & \rstick{\ket{x}}\\
	 \lstick{\ket{y}} & \ctrl{1} & \qw & \rstick{\ket{y}}\\
	 \lstick{\ket{z}} & \targ & \qw  & \rstick{\ket{z\oplus(x\wedge y}}\\
\\ }}
\end{figure}

Esta puerta tiene por matriz:
\begin{equation}
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0
\end{bmatrix}
\end{equation}
Ya hemos visto varias puertas que son reversibles, ahora, llamaremos puertas cuánticas a aquellas aplicaciones que actúan sobre qubits, como vectores de un espacio vectorial complejo y tendrá como representación matricial, matrices unitarias.

Una excepción de las puertas cuánticas sería la operación de medir un qubit, que se suelen realizar al final del circuito y que no son reversibles. Representaremos estas de la siguiente manera en el circuito, donde la doble recta horizontal, representa un cable que lleva información clásica, un bit.
\begin{figure}[h]
\centering
\scalebox{1.0}{
\Qcircuit @C=1.0em @R=0.8em @!R { \\
	 \nghost{cw} & \lstick{\ket{\psi}} & \qw & \meter & \cw & \cw\\
\\ }}
\end{figure}

Hemos visto varios ejemplos de circuitos cuánticos con las puertas cuánticas. Vamos a centrarnos en construir circuitos más complejos combinando las puertas. Podemos tanto concatenar las puertas, realizando una operación tras otra, y operar de manera paralela con ellas, de manera simultanea a un subconjunto del sistema de qubits. Hacemos notar varias restricciones respecto al mundo clásico y es que no permitiremos bucles en los circuitos, de manera que cada circuito funcione de izquierda a derecha y sea acíclico. Además no permitiremos tanto combinar dos cableado en uno, como dividir uno en dos. Veremos en un ejemplo próximo que de hecho no podemos copiar el estado de un qubit a otro.

En cuanto a concatenar las puertas en un circuito, simplemente realizaremos una operación tras otra, de manera ordenada. Si queremos tratar la operación como una matriz, esta se representará por productos de matrices de manera natural. Por ejemplo si queremos aplicar dos veces la puerta CNOT como hemos hecho antes,
\begin{equation}
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 
\end{bmatrix}
\end{equation}
resultando lo que esperábamos, ya que la puerta CNOT es reversible por sí misma, resultando que la concatenación de ella con sigo misma es la identidad.

También podemos realizar operaciones de manera paralela a distintos bits a través de productos tensoriales entre las matrices, siempre cuidando el tamaño de las matrices. Por ejemplo, si queremos aplicar la puerta de Hadamard $H$ a ambos qubits de un sistema de dos qubits, el resultado final será igual que aplicar $(H\otimes H)$ como una puerta al sistema,
\begin{figure}[h]
\centering
\scalebox{1.0}{
\Qcircuit @C=1.0em @R=0.8em @!R { \\
	 \lstick{\ket{x}} & \gate{\mathrm{H}} & \qw \\
	 \lstick{\ket{y}} & \gate{\mathrm{H}} & \qw \\
\\ }}
\end{figure} \\
Recordemos la propiedad del producto tensorial sobre las aplicaciones con la expresión \ref{prtensorial_aplineal}, de esta manera tenemos que,
\begin{equation} \label{matriz_tensorial}
(H\ket{x})\otimes(H\ket{y}) = (H\otimes H)\ket{x\otimes y}
\end{equation}
Vamos a ver un ejemplo más de circuito en el que concatenemos la puerta CNOT con la puerta de Hadamard. Consideramos entonces el circuito:
\begin{figure}[h]
\centering
\scalebox{1.0}{
\Qcircuit @C=1.0em @R=0.2em @!R { \\
	 	\lstick{\ket{x}} & \gate{\mathrm{H}} & \ctrl{1} & \qw & \qw\\
	 	\lstick{\ket{y}} & \qw & \targ & \qw & \qw &\ustick{\ket{\psi'}}\\
\\ }}
\end{figure}\\
Supongamos entonces que comenzaremos con el estado $\ket{00}$, para los otros casos el procedimiento es análogo. Entonces tendríamos que operar la siguiente expresión:
\begin{equation}
\ket{\psi'} = \textrm{CNOT}\cdot(H\otimes I)(\ket{x\otimes y})
\end{equation}
Hacemos notar que a pesar de que no le aplicamos ninguna puerta de manera simultanea a $\ket{y}$ para poder hacer el producto de matrices adecuadamente, es necesario aplicar el producto tensorial a la puerta de Hadamard con la identidad, que no altera el estado de $\ket{y}$.\\
Resolvamos entonces la expresión, con el estado $\ket{00}$ en concreto. Aplicando la propiedad de la expresión \ref{matriz_tensorial} , tenemos que:
\begin{equation}
\ket{\psi'} = \textrm{CNOT}\cdot(H\otimes I)(\ket{00}) = \textrm{CNOT}((H\ket{0}) \otimes (I\ket{0})) = \textrm{CNOT}(\frac{\ket{0}+\ket{1}}{\sqrt{2}}\otimes\ket{0})
\end{equation}
Reordenando la expresión con las propiedades del producto escalar tenemos que:
\begin{equation}
\ket{\psi'} = \textrm{CNOT}(\frac{1}{\sqrt{2}}(\ket{00} + \ket{10}))
\end{equation}
y finamente, aplicando la linealidad de CNOT:
\begin{equation}
\ket{\psi'} = \frac{1}{\sqrt{2}}(\textrm{CNOT}\ket{00} + \textrm{CNOT}\ket{10}) = \frac{1}{\sqrt{2}}(\ket{00} + \ket{11})
\end{equation}
Si recordamos de la sección anterior, hemos producido con este circuito empezando en el estado $\ket{00}$ al estado de Bell que hemos visto.\\
Este desarrollo de naturaleza algebraica que hemos hecho, tiene su equivalente en operaciones matriciales, pues podríamos haber hecho el producto de las matrices:
\begin{equation}
\textrm{CNOT}\cdot(H\otimes I) = \begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 
\end{bmatrix} \cdot \left( \frac{1}{\sqrt{2}}
\begin{bmatrix}
1 & 1 \\
1 & -1 
\end{bmatrix} \otimes
\begin{bmatrix}
1 & 0 \\
0 & 1 
\end{bmatrix}\right)
\end{equation}
Si operamos, obtendremos la siguiente matriz:
\begin{equation}
\frac{1}{\sqrt{2}}
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 \\
1 & 0 & -1 & 0 \\
0 & 1 & 0 & -1 
\end{bmatrix} =
\frac{1}{\sqrt{2}}
\begin{bmatrix}
1 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 \\
0 & 1 & 0 & -1 \\
1 & 0 & -1 & 0
\end{bmatrix}
\end{equation}
Por tanto si operamos con $\ket{00}$, tendremos:
\begin{equation}
\frac{1}{\sqrt{2}}
\begin{bmatrix}
1 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 \\
0 & 1 & 0 & -1 \\
1 & 0 & -1 & 0
\end{bmatrix}
\begin{bmatrix}
1 \\ 0 \\ 0 \\ 0
\end{bmatrix} = 
\frac{1}{\sqrt{2}}
\begin{bmatrix}
1 \\ 0 \\ 0 \\ 1
\end{bmatrix}
\end{equation}
que es la expresión matricial del estado de Bell
\begin{equation}
\frac{\ket{00} + \ket{11}}{\sqrt{2}}
\end{equation}
\newpage

\section{Algoritmos Cuánticos}

En general, los algoritmos cuánticos siguen un esquema común entre ellos. Estos consistirán en:
\begin{itemize}
\item Comenzaremos con una serie de qubits en su estado clásico, es decir, $\ket{0}$ ó $\ket{1}$
\item Luego, serán puestos en superposición de varios estados.
\item Se le aplicarán una serie de operaciones unitarias a través de puertas cuánticas.
\item Y finalmente se medirán los qubits correspondientes y según el algoritmo, se repetirá este proceso varias veces y se compararán los resultados.

\end{itemize}

\subsection{Algoritmo de Deutsch}

El primer algoritmo que veremos y el más simple será el algorimto de Deutsch. Este algoritmo tratará de ver si se cumple cierta propiedad para una función $f:\{0, 1\} \rightarrow \{0, 1\}$, concretamente si es balanceada o constante.

\begin{deff}
Diremos que la función $f:\{0, 1\} \rightarrow \{0, 1\}$ es balanceada si $f(0) \neq f(1)$, y diremos que es constante si $f(0) = f(1)$.
\end{deff}

El algoritmo consistirá en tomar una función $f:\{0, 1\} \rightarrow \{0, 1\}$, con la sólo podemos evaluar la función y obtener la imagen y no sabemos cómo está definido la función y determinar si la función es balanceada o constante.

Para ello tomaremos una puerta cuántica que evaluará la función y observamos que esta tiene que ser reversible. Consideraremos la siguiente operación unitaria $U_f$. A esta función a veces nos referiremos como oráculo, ya que nos evaluará la función indicando la imagen sin que nosotros sepamos la definición de la función.

(Poner circuito)

En la primera entrada $\ket{x}$ será lo que queremos evaluar, y en la segunda entrada $\ket{y}$ actuará como un qubit de control. Tras el cuál, en la primera salida $\ket{x}$ permanecerá igual y en la segunda salida tendremos $\ket{y\oplus f(x)}$.

Observamos que esta puerta cuántica es reversible pues:

(Poner circuito)

El estado $\ket{x, y}$ queda trasformado en $\ket{x, y\oplus f(x)}$ y posteriormente en $\ket{x, (y\oplus f(x))\oplus f(x)} = \ket{x, y\oplus (f(x)\oplus f(x))} = \ket{x, y\oplus 0} = \ket{x, y}$.

El circuito del algoritmo consistirá en lo siguiente:

(Poner circuito)

Esto en términos matriciales sería:
\begin{equation}
(H\oplus I) U_f (H\oplus H) \ket{0, 1} = 
(H\oplus I) U_f (H\oplus H)
\begin{bmatrix}
0 \\ 1 \\ 0 \\ 0
\end{bmatrix}
\end{equation}
Veamos en detalle el resultado al que se llega. Empezamos con el estado $\ket{\varphi_0} = \ket{0, 1}$ que pondremos en superposición con la puerta de Hadamard.
Hadamard transforma a $\ket{0}$ en $\frac{\ket{0} + \ket{1}}{\sqrt{2}}$ y $\ket{1}$ en $\frac{\ket{0} - \ket{1}}{\sqrt{2}}$, por tanto,
\begin{equation}
\ket{\varphi_1} = \left[ \frac{\ket{0} + \ket{1}}{\sqrt{2}} \right] \left[ \frac{\ket{0} - \ket{1}}{\sqrt{2}} \right] =
\frac{\ket{0,0} - \ket{0,1} + \ket{1,0} - \ket{1,1}}{2} = 
\begin{bmatrix}
+\frac{1}{2} \\ -\frac{1}{2} \\ +\frac{1}{2} \\ -\frac{1}{2}
\end{bmatrix}
\end{equation}
Ahora, aplicaremos el oráculo $U_f$ a la expresión $\frac{\ket{0,0} - \ket{0,1} + \ket{1,0} - \ket{1,1}}{2}$ y recordando que $U_f$ no deja de ser una aplicación lineal. Por tanto, tenemos que
\begin{equation}
\ket{\varphi_2} = U_f \frac{\ket{0,0} - \ket{0,1} + \ket{1,0} - \ket{1,1}}{2} = \frac{U_f\ket{0,0} - U_f\ket{0,1} + U_f\ket{1,0} - U_f\ket{1,1}}{2} 
\end{equation}
Recordemos que nuestro oráculo $U_f$ transforma $\ket{x,y}$ en $\ket{x,y\oplus f(x)}$, por lo que
\begin{equation}
\begin{split}
\ket{\varphi_2} =
\frac{\ket{0,0\oplus f(0)} - \ket{0,1\oplus f(0)} + \ket{1, 0\oplus f(1)} - \ket{1, 1\oplus f(1)}}{2} = \\
\frac{\ket{0,f(0)} - \ket{0,\overline{f(0)}} + \ket{1,f(1)} - \ket{1,\overline{f(1)}}}{2}
\end{split}
\end{equation}
donde $\overline{f(x)}$ es el contrario de $f(x)$.

Recordemos que $\ket{x,y}$ no es más que una notación de $\ket{x}\otimes\ket{y}$, por tanto aplicando la propiedad distributiva del producto tensorial por la derecha tenemos
\begin{equation} \label{eq45}
\ket{\varphi_2} =
\frac{\ket{0} \otimes \left[ \ket{f(0)} - \ket{\overline{f(0)}} \right] + \ket{1} \otimes \left[ \ket{f(1)} - \ket{\overline{f(1)}} \right]}{2}
\end{equation}
Observemos en un momento la expresión $\ket{f(x)} -\ket{\overline{f(x)}}$ para $x \in \lbrace 0,1 \rbrace$ y discutimos su valor según el valor de $f(x)$.
\begin{equation}
\ket{f(x)} - \ket{\overline{f(x)}} =
\begin{Bmatrix}
\ket{0} - \ket{1} & \textrm{si} & f(x) = 0 \\
\ket{1} - \ket{0} & \textrm{si} & f(x) = 1
\end{Bmatrix}
\end{equation}
que escribiremos como $(-1)^{f(x)}(\ket{0} - \ket{1})$.

Aplicando esto a la expresión \ref{eq45} tenemos que
\begin{equation}
\ket{\varphi_2} = 
\frac{(-1)^{f(0)} (\ket{0} \otimes \left[ \ket{0} - \ket{1} \right]) + (-1)^{f(1)} (\ket{1} \otimes \left[ \ket{0} - \ket{1} \right])}{2}
\end{equation}
Hacemos uso de la propiedad distributiva por la derecha y reordenamos los escalares para separar la expresión en producto escalar de dos términos
\begin{equation}
\ket{\varphi_2} =
\left[ \frac{(-1)^{f(0)} \ket{0} + (-1)^{f(1)} \ket{1}}{\sqrt{2}} \right]
\left[ \frac{\ket{0} - \ket{1}}{\sqrt{2}} \right]
\end{equation}
Discutamos el valor de la expresión $(-1)^{f(0)} \ket{0} + (-1)^{f(1)} \ket{1}$ según si $f(x)$ es constante o balanceada.
\begin{equation}
\ket{\varphi_2} = 
\begin{cases}
(\pm 1) \left[\frac{\ket{0}+\ket{1}}{2}\right] \left[\frac{\ket{0}-\ket{1}}{2}\right] & \textrm{si } f \textrm{ es constante,} \\
(\pm 1) \left[\frac{\ket{0}-\ket{1}}{2}\right] \left[\frac{\ket{0}-\ket{1}}{2}\right] & \textrm{si } f \textrm{ es balanceada.}
\end{cases}
\end{equation}
Teniendo en cuenta que Hadamard es su propia inversa, llevará $\frac{\ket{0}+\ket{1}}{2}$ a $\ket{0}$ y $\frac{\ket{0}-\ket{1}}{2}$ a $\ket{1}$.
\begin{equation}
\ket{\varphi_3} = 
\begin{cases}
(\pm 1) \ket{0} \left[\frac{\ket{0}-\ket{1}}{2}\right] & \textrm{si } f \textrm{ es constante,} \\
(\pm 1) \ket{1} \left[\frac{\ket{0}-\ket{1}}{2}\right] & \textrm{si } f \textrm{ es balanceada.}
\end{cases}
\end{equation}
Finalmente medimos el qubit superior para determinar si f es constante o balanceada, ya que si sale $\ket{0}$ será constante y si sale $\ket{1}$ será balanceada. Observamos que el signo no afecta a la proceso de medir, pues recordemos que la probabilidad de que sea un estado depende de la norma al cuadrado.

\scalebox{2.0}{
\Qcircuit @C=1.0em @R=0.2em @!R { \\
	 	\nghost{{q}_{0} :  } & \lstick{{\ket{x}} :  } & \gate{\mathrm{H}} & \qw & \qw & \qw\\
	 	\nghost{{q}_{1} :  } & \lstick{{q}_{1} :  } & \gate{\mathrm{H}} & \ctrl{1} & \qw & \qw\\
	 	\nghost{{q}_{2} :  } & \lstick{{q}_{2} :  } & \qw & \targ & \qw & \qw\\
	 	\nghost{\mathrm{{c} :  }} & \lstick{\mathrm{{c} :  }} & \lstick{/_{_{1}}} \cw & \cw & \cw & \cw\\
\\ }}




\newpage

%Espacios de Hilbert Referencias

%Corregir llaves(HECHO)

%En qubits porner la representación de la esfera de Bloch(HECHO)

%Poner ejemplos de qubts multiples

%Poner ejemplos de circuitos

%PONER MÁS PROPIEDADES DEL PRODUCTO TENSORIAL COMO OPERADOR(HECHO)

%Puerta de teleportación ejemplo en algoritmos cuánticos

%En algoritmo de Deutsch indicar la eficiencia

%Traducir entagled

\section{Conclusión}

%e must clarify what we mean by “simulate.” In the classical world, we say that one circuit Circ simulates another circuit Circ	 if for any possible inputs, the output for Circ will be the same for Circ	

%Things in the quantum world are a tad more complicated. Because of the probabilistic nature of quantum computation, the outputs of a circuit are always probabilistic. So we have to reformulate what we mean when we talk about simulate. We shall not worry about this here.

\newpage

\section{Bibliografía}
%Dos libros...

%https://es.wikipedia.org/wiki/Espacio_vectorial

%https://en.wikipedia.org/wiki/Tensor_product

%https://ctan.org/pkg/braket



\end{document}